{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/standenisa/Asistent-Ai/blob/main/IA_lab_4_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laborator 4: Naive Bayes\n",
        "Spre deosebire de algoritmii de regresie logistică sau cei care învață să asocieze direct spațiul caracteristicilor de intrare cu etichete (algoritmi denumiți discriminanți), Naive Bayes este un algoritm de învățare generativ. Acesta modelează distribuțiile $p(x|y)$ și $p(y)$. Dacă variabila $y$ indică prin valorile discrete $0$ sau $1$ două clase distincte, atunci $p(x|y=0)$ modelează distribuția caracteristicilor unei clase, iar $p(x|y=1)$ modelează distribuția celeilalte.\n",
        "\n",
        "Naive Bayes presupune faptul că variabilele de intrare sunt independente condițional, dându-se clasa țintă. Spre deosebire de algoritmii prezentați în laboratoarele anterioare, acest algoritm nu necesită aproximarea iterativă a parametrilor modelului, ci antrenarea se face in timp liniar prin evaluarea unei expresii.\n",
        "\n",
        "Clasificatorul Naive Bayes se bazează pe teorema lui Bayes:\n",
        "\n",
        "$$P(y|x) = \\frac{P(x|y)P(y)}{P(x)}$$\n",
        "unde $P(y|x)$ este probabilitatea lui $y$ dându-se $x$ (denumită probabilitatea posterioară), $P(x|y)$ este probabilitatea lui $x$ dându-se $y$ ( denumită likelihood), iar $P(y)$ și $P(x)$ sunt probabilitățile de a observa $y$, respectiv $x$, necondiționate. Ele se numesc probabilitatea apriori și probabilitatea marginală.\n"
      ],
      "metadata": {
        "id": "Qn0P69CYvMgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificatorul Naive Bayes - clasificarea e-mailurilor\n",
        "\n",
        "În continuare se va realiza un clasificator care estimează probabilitatea ca un e-mail să fie spam, în funcție de cuvintele conținute de acesta. Se pornește de la o bază de date de antrenare care conține e-mailuri etichetate ca spam sau non-spam. Primul pas este specificarea caracteristicilor $X$ care descriu un e-mail. Se va reprezenta un e-mail printr-un vector de caracteristici a cărui lungime este egală cu numărul de cuvinte dintr-un dicționar. Dacă un mail conține cuvântul de la indexul $j$ din dicționar, atunci se va seta $x_j := x_j + 1$.\n",
        "\n",
        "Pentru acest exemplu, baza de date de antrenare **a fost deja preprocesată** în așa fel încât fiecare email marchează în vectorul de caracteristici numărul de apariții al fiecărui cuvânt din dicționarul folosit.\n",
        "Exercițiul din acest laborator folosește un dicționar de 2500 de cuvinte pentru caracteristicile fiecărui e-mail în parte. Astfel, vectorul de caracteristici $X$ din baza de date de antrenare va avea următoarea formă: $(\\text{nr_exemple} \\times \\text{dim. dicționar})$. Dacă vor fi folosite 700 de emailuri și un dicționar de 2500 de cuvinte pentru datele de antrenare, atunci dimensiunea vectorului de caracteristici $X$ va fi: $(700 \\times 2500)$.\n",
        "\n",
        "## Exemplu de procesare pentru un e-mail\n",
        "Să zicem că dorim să procesăm următorul e-mail:\n",
        "\n",
        "\n",
        "> Buy now quick! Save 100 dollars with our special deal. Buy 10 pieces and get one free.\n",
        "\n",
        "Iar pentru acest exemplu, presupunem că folosim un dicționar care conține toate cuvintele din acest mail. Așadar vom avea vectorul de caracteristici pentru acest e-mail:\n",
        "$$x = \\begin{bmatrix}1 \\\\ \\vdots \\\\ 2 \\\\ \\vdots \\\\ 1 \\\\ \\vdots\\end{bmatrix} = \\begin{bmatrix}\\text{and} \\\\ \\vdots \\\\ \\text{buy} \\\\ \\vdots \\\\ \\text{with} \\\\ \\vdots \\end{bmatrix}$$\n",
        "\n",
        "## Implementarea clasificatorului Naive Bayes\n",
        "\n",
        "Probabilitatea pe care vrem să o estimăm este probabilitatea ca un mesaj e-mail să fie spam, dându-se cuvintele conținute în respectivul e-mail: $P(y=1|x)$:\n",
        "$$P(y=1|x) = \\frac{P(x|y=1) \\cdot P(y=1)}{P(x)} = \\frac{\\prod_{j=1}^nP(x_j|y=1) \\cdot P(y=1)}{\\prod_{j=1}^nP(x_j|y=1) \\cdot P(y=1) + \\prod_{j=1}^nP(x_j|y=0) \\cdot P(y=0)}$$\n",
        "unde:\n",
        "*   $P(y=1|x)$ este probabilitatea ca un e-mail să fie spam, dându-se cuvintele conținând cuvintele $x$.\n",
        "*   $P(x_j|y=1)$ reprezintă probabilitatea ca un cuvânt $x_j$ din dicționar să aparțină unui mesaj spam.\n",
        "*   $P(y=1)$ reprezintă probabilitatea ca un e-mail să fie spam.\n",
        "*   $P(y=0)$ este probabilitatea ca un mesaj să nu fie spam.\n",
        "*   $P(x_j)$ reprezintă probabilitatea apariției cuvântului $x_j$.\n",
        "\n",
        "Se poate calcula probabilitatea de apariție unui cuvânt dându-se un e-mail spam:\n",
        "$$P(x_j|y=1) = \\frac{N_{x_j|y=1} + \\alpha}{N_{y=1} + \\alpha \\cdot N_V}$$\n",
        "unde:\n",
        "*  $P(x_j|y=1)$ este probabilitatea de apariție a cuvântului $x_j$ în mesaje spam.\n",
        "*  $N_{x_j|y=1}$ este numărul de apariții ale cuvântului $x_j$ din mesajele spam.\n",
        "*  $\\alpha$ este un parametru de netezire, denumit netezirea Laplace.\n",
        "*  $N_{y=1}$ este numărul total de cuvinte din toate mesajele spam.\n",
        "*  $N_V$ este numărul total de cuvinte din vocabular.\n",
        "\n",
        "Analog se poate calcula probabilitatea de apariție a aceluiași cuvânt într-un mesaj non-spam:\n",
        "$$P(x_j|y=0) = \\frac{N_{x_j|y=0} + \\alpha}{N_{y=0} + \\alpha \\cdot N_V}$$\n",
        "\n",
        "Prima oară se calculează constantele:\n",
        "\n",
        "\n",
        "*   $N_{y=1}$ - numărul de mesaje spam.\n",
        "*   $N_V$ - dimensiunea vocabularului.\n",
        "*   $N_{y=0}$ - numărul de mesaje non-spam.\n",
        "*   $P(y=1)$ - probabilitatea ca un e-mail (din baza de date) să fie spam."
      ],
      "metadata": {
        "id": "65KlqCcA61bO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66Ppylz1vLro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab877d1a-3fb0-46b5-9d27-1f1f3d983ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numarul total de cuvinte din mailurile spam este: 91566.0\n",
            "In baza de date de antrenare se afla 700 emailuri. Sunt cunoscute 2500 de cuvinte distincte.\n",
            "Numarul total de cuvinte din mailurile non-spam este: 61762.0\n",
            "Factorul de netezire este: 1.0\n",
            "Probabilitatea ca un e-mail din baza de date sa fie spam este de 0.5\n",
            "Probabilitatea ca un e-mail din baza de date sa fie non-spam este de 0.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Incarcarea bazei de date de antrenare\n",
        "x_train = np.loadtxt('train-features-full.txt', delimiter=' ')\n",
        "y_train = np.loadtxt('train-labels.txt', delimiter=' ')\n",
        "\n",
        "# Stocarea numarului de exemple de antrenare\n",
        "num_train = x_train.shape[0]\n",
        "\n",
        "# Gasirea indecsilor pentru etichetele spam, respectiv non-spam\n",
        "spam_indices = np.nonzero(y_train==1)[0]\n",
        "nonspam_indices = np.nonzero(y_train==0)[0]\n",
        "\n",
        "N_Y1 = np.sum(x_train[spam_indices])\n",
        "print(f\"Numarul total de cuvinte din mailurile spam este: {N_Y1}\")\n",
        "\n",
        "N_V = x_train[0].shape[0]\n",
        "print(f\"In baza de date de antrenare se afla {num_train} emailuri. Sunt cunoscute {N_V} de cuvinte distincte.\")\n",
        "\n",
        "N_Y0 = np.sum(x_train[nonspam_indices])\n",
        "print(f\"Numarul total de cuvinte din mailurile non-spam este: {N_Y0}\")\n",
        "\n",
        "# Factorul de netezire Laplace\n",
        "alpha = 1.0\n",
        "print(f\"Factorul de netezire este: {alpha}\")\n",
        "\n",
        "P_Y1 = spam_indices.shape[0] / num_train\n",
        "P_Y0 = nonspam_indices.shape[0] / num_train\n",
        "\n",
        "print(f\"Probabilitatea ca un e-mail din baza de date sa fie spam este de {P_Y1}\")\n",
        "print(f\"Probabilitatea ca un e-mail din baza de date sa fie non-spam este de {P_Y0}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apoi se calculează pentru fiecare cuvânt din dicționar $P(x_j|y=1)$, respectiv $P(x_j|y=0)$."
      ],
      "metadata": {
        "id": "v8DsVZUavgCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_spam = (np.sum(x_train[spam_indices], axis=0) + alpha) / (N_Y1 + alpha * N_V)\n",
        "P_nonspam = (np.sum(x_train[nonspam_indices], axis=0) + alpha) / (N_Y0 + alpha * N_V)"
      ],
      "metadata": {
        "id": "jb57XAzOwXV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apoi se verifică din baza de date de test fiecare e-mail în parte. Pentru determinarea probabilității ca un e-mail să fie spam sau nonspam nu este necesar calculul numitorului din ecuația $P(y=1|x)$. De asemenea, pentru eficientizarea calculului, se aplică logaritmul peste densitățile de probabilitate $P(x_j|y=1)$, respectiv $P(x_j|y=0)$:\n",
        "\n",
        "$$log(P(y=1|x)) \\propto \\sum_{j=1}^n\\text{log}(P(x_j|y=1)) + \\text{log}(P(y=1))$$\n",
        "respectiv\n",
        "$$log(P(y=0|x)) \\propto \\sum_{j=1}^n\\text{log}(P(x_j|y=0)) + \\text{log}(P(y=0))$$\n",
        "unde simbolul $\\propto$ reprezintă proporționalitatea.\n",
        "\n"
      ],
      "metadata": {
        "id": "-dhOxYsry_6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.loadtxt('test-features-full.txt', delimiter=' ')\n",
        "y_test = np.loadtxt('test-labels.txt', delimiter=' ')\n",
        "\n",
        "P_spam_messages = np.dot(x_test, np.log(P_spam)) + np.log(P_Y1)\n",
        "P_nonspam_messages = np.dot(x_test, np.log(P_nonspam)) + np.log(1. - P_Y1)\n"
      ],
      "metadata": {
        "id": "m1P_n4_NzKA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "După ce au fost calculate probabilitățile ca e-mailurile din baza de date de test să fie spam și nonspam, se compară rezultatul algoritmului Naive Bayes cu valorile țintă ale setului de date de test."
      ],
      "metadata": {
        "id": "eyaOsQFuSdwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variabila res contine pentru fiecare email din baza de date de test True daca\n",
        "# acel email este spam, respectiv False in caz contrar.\n",
        "res = P_spam_messages > P_nonspam_messages\n",
        "\n",
        "# Se numara documentele clasificate gresit\n",
        "y_test = y_test.astype(bool)\n",
        "num_wrong = res != y_test\n",
        "\n",
        "print(f\"Din emailurile stocate in baza de date de test au fost clasificate gresit \\\n",
        "{np.count_nonzero(num_wrong)} emailuri\")\n",
        "print(f\"Eroarea statistica este de {np.count_nonzero(num_wrong) / y_test.shape[0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ3PdK2BTqe-",
        "outputId": "30e16477-994f-458a-ddc3-dcb3cdac3825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Din emailurile stocate in baza de date de test au fost clasificate gresit 5 emailuri\n",
            "Eroarea statistica este de 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exerciții propuse\n",
        "\n",
        "Fișierul SMSSpamCollection conține 5574 de mesaje SMS dintr-o bază de date, etichetate ca spam sau non-spam.\n",
        "\n",
        "1.  Să se citească fișierul SMSSpamCollection și să se curețe fiecare mesaj în parte în felul următor: caracterele non-alfanumerice, respectiv cifrele să fie eliminate. Să se treacă toate mesajele în lowercase.\n",
        "2.  Să se elimine cuvintele de legătură din fiecare mesaj.\n",
        "3.  Să se definească un vocabular pe baza fiecărui cuvânt din mesajele din baza de date (vocabularul conține fiecare cuvânt unic din baza de date).\n",
        "4.  Să se definească baza de date de antrenare în mod similar cu cea din exemplul anterior (fiecare cuvânt dintr-un mesaj incrementează valoarea din dicționarul folosit pentru variabila $x$; pentru $y$, se va considera pentru fiecare mesaj în parte $y=1$ dacă mesajul este considerat spam, respectiv $y=0$ în caz contrar). Baza de date de antrenare va conține primele 5000 de exemple $(x,y)$. Restul datelor vor fi folosite pentru testarea algoritmului.\n",
        "5.  Să se clasifice fiecare mesaj din baza de date de test în spam sau nonspam.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bzhd9UGyz8cJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observații\n",
        "Pentru a elimina din mesaje caracterele non-alfanumerice și cifrele se folosesc **regular expressions** (regex). Acestea se folosesc cu ajutorul modulului **re**:\n",
        "\n",
        "```\n",
        "import re\n",
        "```\n",
        "Pentru a elimina cuvintele de legătură, se folosește modulul **nltk**. Un exemplu de utilizare este:\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "s = set(stopwords.words('english'))\n",
        "```\n",
        "Setul **s** din secțiunea de cod anterioară conține cuvintele din limba engleză considerate de legătură.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QEjoXW6a0uMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importul modulelor necesare\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Filtrarea textului mesajelor\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Curata si normalizeaza textul conform cerintelor:\n",
        "    - elimina caractere non-alfanumerice si cifre\n",
        "    - converteste la lowercase\n",
        "    \"\"\"\n",
        "    # Converteste la lowercase\n",
        "    text = text.lower()\n",
        "    # Elimina cifrele si caracterele non-alfanumerice (pastreaza doar litere si spatii)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Elimina spatiile multiple\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Citirea fisierului si procesarea mesajelor\n",
        "def load_sms_data(filepath='/content/sample_data/SMSSpamCollection'):\n",
        "    \"\"\"Incarca datele din fisier.\"\"\"\n",
        "    messages = []\n",
        "    labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 2:\n",
        "                label, message = parts\n",
        "                labels.append(1 if label == 'spam' else 0)\n",
        "                messages.append(preprocess_text(message))\n",
        "\n",
        "    return messages, np.array(labels)\n",
        "\n",
        "# Incarcarea datelor\n",
        "messages, labels = load_sms_data()\n",
        "\n",
        "print(f\"Total SMS-uri incarcate: {len(messages)}\")\n",
        "print(f\"Spam: {np.sum(labels)}, Ham: {len(labels) - np.sum(labels)}\")\n",
        "\n",
        "# Eliminarea cuvintelor de legatura: \"a\", \"the\", ...\n",
        "# Definim manual setul de stop words (cuvinte de legatura)\n",
        "stop_words = {\n",
        "    'a', 'an', 'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
        "    'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',\n",
        "    'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
        "    'would', 'could', 'should', 'may', 'might', 'must', 'can', 'i', 'you',\n",
        "    'he', 'she', 'it', 'we', 'they', 'this', 'that', 'these', 'those',\n",
        "    'my', 'your', 'his', 'her', 'its', 'our', 'their', 'me', 'him', 'us',\n",
        "    'them', 'what', 'which', 'who', 'when', 'where', 'why', 'how', 'all',\n",
        "    'each', 'every', 'both', 'few', 'more', 'most', 'other', 'some', 'such',\n",
        "    'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n",
        "    'just', 'dont', 'now', 'get', 'got', 'go', 'goes', 'went'\n",
        "}\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"Elimina cuvintele de legatura.\"\"\"\n",
        "    words = text.split()\n",
        "    return ' '.join([word for word in words if word not in stop_words])\n",
        "\n",
        "# Aplicarea eliminarii cuvintelor de legatura\n",
        "messages = [remove_stopwords(msg) for msg in messages]\n",
        "\n",
        "# Construirea vocabularului - fiecare cuvant unic din baza de date\n",
        "all_words = []\n",
        "for message in messages:\n",
        "    all_words.extend(message.split())\n",
        "\n",
        "# Construirea vocabularului (cuvinte care apar de cel putin 1 ori)\n",
        "word_counts = Counter(all_words)\n",
        "vocabulary = sorted(list(word_counts.keys()))  # vocabular sortat alfabetic\n",
        "\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "\n",
        "print(f\"Dimensiunea vocabularului: {len(vocabulary)}\")\n",
        "\n",
        "# Transformarea mesajelor din text in vocabular\n",
        "def text_to_vector(text, word_to_idx):\n",
        "    \"\"\"Converteste un text intr-un vector de frecvente.\n",
        "    Fiecare cuvant dintr-un mesaj incrementeaza valoarea din dictionar.\"\"\"\n",
        "    vector = np.zeros(len(word_to_idx))\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        if word in word_to_idx:\n",
        "            vector[word_to_idx[word]] += 1\n",
        "    return vector\n",
        "\n",
        "# Construirea datelor de antrenare\n",
        "# Primele 5000 de exemple pentru antrenare\n",
        "X = np.array([text_to_vector(msg, word_to_idx) for msg in messages])\n",
        "y = labels\n",
        "\n",
        "# Definirea bazei de date de antrenare si testare\n",
        "x_train = X[:5000]\n",
        "y_train = y[:5000]\n",
        "\n",
        "# Definirea x_test\n",
        "x_test = X[5000:]\n",
        "\n",
        "# Definirea y_test\n",
        "y_test = y[5000:]\n",
        "\n",
        "print(f\"\\nDimensiunea setului de antrenare: {x_train.shape}\")\n",
        "print(f\"Dimensiunea setului de testare: {x_test.shape}\")\n",
        "\n",
        "'''\n",
        "Rularea algoritmului Naive Bayes pentru exemplul cu SMS-uri spam/nonspam.\n",
        "Codul prezentat anterior pentru exemplul cu email-uri ar trebui sa functioneze\n",
        "si pentru acest exemplu cu SMS-uri.\n",
        "'''\n",
        "num_train = x_train.shape[0]\n",
        "\n",
        "assert num_train >= 5000, \"Numarul de exemple de antrenare nu coincide cu baza de date cu SMS-uri\"\n",
        "\n",
        "# Gasirea indecsilor pentru etichetele spam, respectiv non-spam\n",
        "spam_indices = np.nonzero(y_train==1)[0]\n",
        "nonspam_indices = np.nonzero(y_train==0)[0]\n",
        "\n",
        "N_Y1 = np.sum(x_train[spam_indices])\n",
        "print(f\"\\nNumarul total de cuvinte din SMS-urile spam este: {N_Y1}\")\n",
        "\n",
        "N_V = x_train[0].shape[0]\n",
        "print(f\"In baza de date de antrenare se afla {num_train} SMS-uri. Sunt cunoscute {N_V} de cuvinte distincte.\")\n",
        "\n",
        "N_Y0 = np.sum(x_train[nonspam_indices])\n",
        "print(f\"Numarul total de cuvinte din SMS-urile non-spam este: {N_Y0}\")\n",
        "\n",
        "# Factorul de netezire Laplace\n",
        "alpha = 1.0\n",
        "print(f\"Factorul de netezire este: {alpha}\")\n",
        "\n",
        "P_Y1 = spam_indices.shape[0] / num_train\n",
        "P_Y0 = nonspam_indices.shape[0] / num_train\n",
        "\n",
        "print(f\"Probabilitatea ca un SMS din baza de date sa fie spam este de {P_Y1}\")\n",
        "print(f\"Probabilitatea ca un SMS din baza de date sa fie non-spam este de {P_Y0}\")\n",
        "\n",
        "P_spam = (np.sum(x_train[spam_indices], axis=0) + alpha) / (N_Y1 + alpha * N_V)\n",
        "P_nonspam = (np.sum(x_train[nonspam_indices], axis=0) + alpha) / (N_Y0 + alpha * N_V)\n",
        "\n",
        "P_spam_messages = np.dot(x_test, np.log(P_spam)) + np.log(P_Y1)\n",
        "P_nonspam_messages = np.dot(x_test, np.log(P_nonspam)) + np.log(1. - P_Y1)\n",
        "\n",
        "# Variabila res contine pentru fiecare SMS din baza de date de test True daca\n",
        "# acel SMS este spam, respectiv False in caz contrar.\n",
        "res = P_spam_messages > P_nonspam_messages\n",
        "\n",
        "# Se numara documentele clasificate gresit\n",
        "y_test = y_test.astype(bool)\n",
        "num_wrong = res != y_test\n",
        "\n",
        "print(f\"\\nDin SMS-urile stocate in baza de date de test au fost clasificate gresit \\\n",
        "{np.count_nonzero(num_wrong)} SMS-uri (din totalul de {y_test.shape[0]} SMS-uri).\")\n",
        "print(f\"Eroarea statistica este de {np.count_nonzero(num_wrong) / y_test.shape[0]:.2f}\")"
      ],
      "metadata": {
        "id": "gI2bRNTMbRnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af622f51-a742-4b75-9add-a8e3e23d465c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total SMS-uri incarcate: 5574\n",
            "Spam: 747, Ham: 4827\n",
            "Dimensiunea vocabularului: 8535\n",
            "\n",
            "Dimensiunea setului de antrenare: (5000, 8535)\n",
            "Dimensiunea setului de testare: (574, 8535)\n",
            "\n",
            "Numarul total de cuvinte din SMS-urile spam este: 9821.0\n",
            "In baza de date de antrenare se afla 5000 SMS-uri. Sunt cunoscute 8535 de cuvinte distincte.\n",
            "Numarul total de cuvinte din SMS-urile non-spam este: 36412.0\n",
            "Factorul de netezire este: 1.0\n",
            "Probabilitatea ca un SMS din baza de date sa fie spam este de 0.1346\n",
            "Probabilitatea ca un SMS din baza de date sa fie non-spam este de 0.8654\n",
            "\n",
            "Din SMS-urile stocate in baza de date de test au fost clasificate gresit 15 SMS-uri (din totalul de 574 SMS-uri).\n",
            "Eroarea statistica este de 0.03\n"
          ]
        }
      ]
    }
  ]
}